var documenterSearchIndex = {"docs":
[{"location":"functionality/device/#AbstractDeviceArray-1","page":"AbstractDeviceArray","title":"AbstractDeviceArray","text":"","category":"section"},{"location":"functionality/device/#","page":"AbstractDeviceArray","title":"AbstractDeviceArray","text":"TODO: describe functionality","category":"page"},{"location":"functionality/host/#AbstractGPUArray-1","page":"AbstractGPUArray","title":"AbstractGPUArray","text":"","category":"section"},{"location":"functionality/host/#","page":"AbstractGPUArray","title":"AbstractGPUArray","text":"TODO: describe functionality","category":"page"},{"location":"interface/#Interface-1","page":"Interface","title":"Interface","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"To extend the above functionality to a new array type, you should use the types and implement the interfaces listed on this page. GPUArrays is design around having two different array types to represent a GPU array: one that only ever lives on the host, and one that actually can be instantiated on the device (i.e. in kernels).","category":"page"},{"location":"interface/#Host-side-1","page":"Interface","title":"Host-side","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"Your host-side array type should build on the AbstractGPUArray supertype:","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"AbstractGPUArray","category":"page"},{"location":"interface/#GPUArrays.AbstractGPUArray","page":"Interface","title":"GPUArrays.AbstractGPUArray","text":"AbstractGPUArray{T, N} <: DenseArray{T, N}\n\nSupertype for N-dimensional GPU arrays (or array-like types) with elements of type T. Instances of this type are expected to live on the host, see AbstractDeviceArray for device-side objects.\n\n\n\n\n\n","category":"type"},{"location":"interface/#","page":"Interface","title":"Interface","text":"First of all, you should implement operations that are expected to be defined for any AbstractArray type. Refer to the Julia manual for more details, or look at the JLArray reference implementation.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"To be able to actually use the functionality that is defined for AbstractGPUArrays, you should provide implementations of the following interfaces:","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"GPUArrays.unsafe_reinterpret","category":"page"},{"location":"interface/#GPUArrays.unsafe_reinterpret","page":"Interface","title":"GPUArrays.unsafe_reinterpret","text":"unsafe_reinterpret(T, a, dims)\n\nReinterpret the array a to have a new element type T and size dims.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Devices-1","page":"Interface","title":"Devices","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"GPUArrays.device\nGPUArrays.synchronize","category":"page"},{"location":"interface/#GPUArrays.device","page":"Interface","title":"GPUArrays.device","text":"device(A::AbstractArray)\n\nGets the device associated to the Array A\n\n\n\n\n\n","category":"function"},{"location":"interface/#GPUArrays.synchronize","page":"Interface","title":"GPUArrays.synchronize","text":"synchronize(A::AbstractArray)\n\nBlocks until all operations are finished on A\n\n\n\n\n\n","category":"function"},{"location":"interface/#Execution-1","page":"Interface","title":"Execution","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"GPUArrays.AbstractGPUBackend\nGPUArrays.backend","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"GPUArrays._gpu_call","category":"page"},{"location":"interface/#Linear-algebra-1","page":"Interface","title":"Linear algebra","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"GPUArrays.blas_module\nGPUArrays.blasbuffer","category":"page"},{"location":"interface/#Device-side-1","page":"Interface","title":"Device-side","text":"","category":"section"},{"location":"interface/#","page":"Interface","title":"Interface","text":"To work with GPU memory on the device itself, e.g. within a kernel, we need a different type: Most functionality will behave differently when running on the GPU, e.g., accessing memory directly instead of copying it to the host. We should also take care not to call into any host library, such as the Julia runtime or the system's math library.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"AbstractDeviceArray","category":"page"},{"location":"interface/#GPUArrays.AbstractDeviceArray","page":"Interface","title":"GPUArrays.AbstractDeviceArray","text":"AbstractDeviceArray{T, N} <: DenseArray{T, N}\n\nSupertype for N-dimensional GPU arrays (or array-like types) with elements of type T. Instances of this type are expected to live on the device, see AbstractGPUArray for device-side objects.\n\n\n\n\n\n","category":"type"},{"location":"interface/#","page":"Interface","title":"Interface","text":"Your device array type should again implement the core elements of the AbstractArray interface, such as indexing and certain getters. Refer to the Julia manual for more details, or look at the JLDeviceArray reference implementation.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"You should also provide implementations of several \"GPU intrinsics\". To make sure the correct implementation is called, the first argument to these intrinsics will be the kernel state object from before.","category":"page"},{"location":"interface/#","page":"Interface","title":"Interface","text":"GPUArrays.LocalMemory\nGPUArrays.synchronize_threads\nGPUArrays.blockidx_x\nGPUArrays.blockidx_y\nGPUArrays.blockidx_z\nGPUArrays.blockdim_x\nGPUArrays.blockdim_y\nGPUArrays.blockdim_z\nGPUArrays.threadidx_x\nGPUArrays.threadidx_y\nGPUArrays.threadidx_z\nGPUArrays.griddim_x\nGPUArrays.griddim_y\nGPUArrays.griddim_z","category":"page"},{"location":"interface/#GPUArrays.LocalMemory","page":"Interface","title":"GPUArrays.LocalMemory","text":"Creates a block local array pointer with T being the element type and N the length. Both T and N need to be static! C is a counter for approriately get the correct Local mem id in CUDAnative. This is an internal method which needs to be overloaded by the GPU Array backends\n\n\n\n\n\n","category":"function"},{"location":"interface/#GPUArrays.synchronize_threads","page":"Interface","title":"GPUArrays.synchronize_threads","text":" synchronize_threads(state)\n\nin CUDA terms __synchronize in OpenCL terms: barrier(CLK_LOCAL_MEM_FENCE)\n\n\n\n\n\n","category":"function"},{"location":"testsuite/#Test-suite-1","page":"Test suite","title":"Test suite","text":"","category":"section"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"GPUArrays provides an extensive test suite that covers all of the functionality that should be available after implementing the required interfaces. This test suite is part of this package, but for dependency reasons it is not available when importing the package. Instead, you should include the code from your runtests.jl as follows:","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"import GPUArrays\ngpuarrays = pathof(GPUArrays)\ngpuarrays_root = dirname(dirname(gpuarrays))\ninclude(joinpath(gpuarrays_root, \"test\", \"testsuite.jl\"))","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"This however implies that the test system will not know about extra dependencies that are required by the test suite. To remedy this, you should add the following dependencies to your Project.toml:","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"[extras]\nFFTW = \"7a1cc6ca-52ef-59f5-83cd-3a7055c09341\"\nFillArrays = \"1a297f60-69ca-5386-bcde-b61e274b549b\"\nForwardDiff = \"f6369f11-7733-5829-9624-2563aa707210\"\n...\n\n[targets]\ntest = [..., \"FFTW\", \"ForwardDiff\", \"FillArrays\"]","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"With this set-up, you can run the test suite like this:","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"using GPUArrays, GPUArrays.TestSuite\nTestSuite.run_tests(MyGPUArrayType)","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"If you don't want to run the whole suite, you can also run parts of it:","category":"page"},{"location":"testsuite/#","page":"Test suite","title":"Test suite","text":"T = JLArray\nGPUArrays.allowscalar(false) # fail tests when slow indexing path into Array type is used.\n\nTestSuite.run_gpuinterface(T) # interface functions like gpu_call, threadidx, etc\nTestSuite.run_base(T) # basic functionality like launching a kernel on the GPU and Base operations\nTestSuite.run_blas(T) # tests the blas interface\nTestSuite.run_broadcasting(T) # tests the broadcasting implementation\nTestSuite.run_construction(T) # tests all kinds of different ways of constructing the array\nTestSuite.run_fft(T) # fft tests\nTestSuite.run_linalg(T) # linalg function tests\nTestSuite.run_mapreduce(T) # mapreduce sum, etc\nTestSuite.run_indexing(T) # indexing tests","category":"page"},{"location":"#GPUArrays.jl-1","page":"Home","title":"GPUArrays.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"GPUArrays is a package that provides reusable GPU array functionality for Julia's various GPU backends. Think of it as the AbstractArray interface from Base, but for GPU array types. It allows you to write generic julia code for all GPU platforms and implements common algorithms for the GPU. Like Julia Base, this includes BLAS wrapper, FFTs, maps, broadcasts and mapreduces. So when you inherit from GPUArrays and overload the interface correctly, you will get a lot of functionality for free. This will allow to have multiple GPUArray implementation for different purposes, while maximizing the ability to share code.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"This package is not intended for end users! Instead, you should use one of the packages that builds on GPUArrays.jl. There is currently only a single package that actively builds on these interfaces, namely CuArrays.jl.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In this documentation, you will find more information on the interface that you are expected to implement, the functionality you gain by doing so, and the test suite that is available to verify your implementation. GPUArrays.jl also provides a reference implementation of these interfaces on the CPU: The JLArray array type uses Julia's parallel programming functionality to simulate GPU execution, and will be used throughout this documentation to illustrate functionality.","category":"page"}]
}
