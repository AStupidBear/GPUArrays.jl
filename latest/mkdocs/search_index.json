{
    "docs": [
        {
            "location": "/", 
            "text": "GPUArrays Documentation\n\n\n\n\nAbstract GPU interface\n\n\nGPUArrays supports different platforms like CUDA and OpenCL, which all have different names for function that offer the same functionality on the hardware. E.g. how to call a function on the GPU, how to get the thread index etc. GPUArrays offers an abstract interface for these functions which are overloaded by the packages like \nCLArrays\n and \nCuArrays\n. This makes it possible to write generic code that can be run on all hardware. GPUArrays itself even contains a pure Julia implementation of this interface. The julia reference implementation is also a great way to debug your GPU code, since it offers many more errors and debugging information compared to the GPU backends - which mostly silently error or give cryptic errors (so far). You can use the reference implementation by using the \nGPUArrays.JLArray\n type.\n\n\nThe functions that are currently part of the interface:\n\n\nThe low level dim + idx function, with a similar naming as in CUDA (with \n*\n indicating \n(x, y, z)\n):\n\n\nblockidx_*(state), blockdim_*(state), threadidx_*(state), griddim_*(state)\n# Known in OpenCL as:\nget_group_id,      get_local_size,    get_local_id,       get_num_groups\n\n\n\n\ngpu_call(f, A::GPUArray, args::Tuple, configuration = length(A))\n\n\nlinear_index(state)\n\nglobal_size(state)\n\n@linearidx(A, statesym = :state)\n\n@cartesianidx(A, statesym = :state)\n\n\nsynchronize_threads(state)\n\n\ndevice(A::AbstractArray)\nsynchronize(A::AbstractArray)", 
            "title": "Home"
        }, 
        {
            "location": "/#gpuarrays-documentation", 
            "text": "", 
            "title": "GPUArrays Documentation"
        }, 
        {
            "location": "/#abstract-gpu-interface", 
            "text": "GPUArrays supports different platforms like CUDA and OpenCL, which all have different names for function that offer the same functionality on the hardware. E.g. how to call a function on the GPU, how to get the thread index etc. GPUArrays offers an abstract interface for these functions which are overloaded by the packages like  CLArrays  and  CuArrays . This makes it possible to write generic code that can be run on all hardware. GPUArrays itself even contains a pure Julia implementation of this interface. The julia reference implementation is also a great way to debug your GPU code, since it offers many more errors and debugging information compared to the GPU backends - which mostly silently error or give cryptic errors (so far). You can use the reference implementation by using the  GPUArrays.JLArray  type.  The functions that are currently part of the interface:  The low level dim + idx function, with a similar naming as in CUDA (with  *  indicating  (x, y, z) ):  blockidx_*(state), blockdim_*(state), threadidx_*(state), griddim_*(state)\n# Known in OpenCL as:\nget_group_id,      get_local_size,    get_local_id,       get_num_groups  gpu_call(f, A::GPUArray, args::Tuple, configuration = length(A))\n\n\nlinear_index(state)\n\nglobal_size(state)\n\n@linearidx(A, statesym = :state)\n\n@cartesianidx(A, statesym = :state)\n\n\nsynchronize_threads(state)\n\n\ndevice(A::AbstractArray)\nsynchronize(A::AbstractArray)", 
            "title": "Abstract GPU interface"
        }
    ]
}