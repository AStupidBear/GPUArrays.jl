{
    "docs": [
        {
            "location": "/", 
            "text": "GPUArrays Documentation\n\n\n\n\nAbstract GPU interface\n\n\nGPUArrays supports different platforms like CUDA and OpenCL, which all have different names for function that offer the same functionality on the hardware. E.g. how to call a function on the GPU, how to get the thread index etc. GPUArrays offers an abstract interface for these functions which are overloaded by the packages like \nCLArrays\n and \nCuArrays\n. This makes it possible to write generic code that can be run on all hardware. GPUArrays itself even contains a pure Julia implementation of this interface. The julia reference implementation is also a great way to debug your GPU code, since it offers many more errors and debugging information compared to the GPU backends - which mostly silently error or give cryptic errors (so far). You can use the reference implementation by using the \nGPUArrays.JLArray\n type.\n\n\nThe functions that are currently part of the interface:\n\n\nThe low level dim + idx function, with a similar naming scheme as in CUDA:\n\n\n# with * being either of x, y or z\nblockidx_*(state), blockdim_*(state), threadidx_*(state), griddim_*(state)\n# Known in OpenCL as:\nget_group_id,      get_local_size,    get_local_id,       get_num_groups\n\n\n\n\n#\n\n\nGPUArrays.gpu_call\n \n \nFunction\n.\n\n\nCalls function \nf\n on the GPU. \nA\n must be an GPUArray and will help to dispatch to the correct GPU backend and supplies queues and contexts. Calls kernel with \nkernel(state, args...)\n, where state is dependant on the backend and can be used for e.g getting an index into A with \nlinear_index(state)\n. Optionally, launch configuration can be supplied in the following way:\n\n\n1) A single integer, indicating how many work items (total number of threads) you want to launch.\n    in this case `linear_index(state)` will be a number in the range 1:configuration\n2) Pass a tuple of integer tuples to define blocks and threads per blocks!\n\n\n\n\nsource\n\n\n#\n\n\nGPUArrays.linear_index\n \n \nMethod\n.\n\n\nlinear index in a GPU kernel (equal to  OpenCL.get_global_id)\n\n\nsource\n\n\n#\n\n\nGPUArrays.global_size\n \n \nMethod\n.\n\n\nGlobal size == blockdim * griddim == total number of kernel execution\n\n\nsource\n\n\n#\n\n\nGPUArrays.@linearidx\n \n \nMacro\n.\n\n\nMacro form of \nlinear_index\n, which returns when out of bounds\n\n\nsource\n\n\n#\n\n\nGPUArrays.@cartesianidx\n \n \nMacro\n.\n\n\nLike \n@linearidx\n, but returns an N-dimensional \nNTuple{ndim(A), Cuint}\n as index\n\n\nsource\n\n\n#\n\n\nGPUArrays.synchronize_threads\n \n \nMethod\n.\n\n\nin CUDA terms \n__synchronize\n\n\nsource\n\n\n#\n\n\nGPUArrays.device\n \n \nMethod\n.\n\n\nGets the device associated to the Array \nA\n\n\nsource\n\n\n#\n\n\nGPUArrays.synchronize\n \n \nMethod\n.\n\n\nBlocks until all operations are finished on \nA\n\n\nsource", 
            "title": "Home"
        }, 
        {
            "location": "/#gpuarrays-documentation", 
            "text": "", 
            "title": "GPUArrays Documentation"
        }, 
        {
            "location": "/#abstract-gpu-interface", 
            "text": "GPUArrays supports different platforms like CUDA and OpenCL, which all have different names for function that offer the same functionality on the hardware. E.g. how to call a function on the GPU, how to get the thread index etc. GPUArrays offers an abstract interface for these functions which are overloaded by the packages like  CLArrays  and  CuArrays . This makes it possible to write generic code that can be run on all hardware. GPUArrays itself even contains a pure Julia implementation of this interface. The julia reference implementation is also a great way to debug your GPU code, since it offers many more errors and debugging information compared to the GPU backends - which mostly silently error or give cryptic errors (so far). You can use the reference implementation by using the  GPUArrays.JLArray  type.  The functions that are currently part of the interface:  The low level dim + idx function, with a similar naming scheme as in CUDA:  # with * being either of x, y or z\nblockidx_*(state), blockdim_*(state), threadidx_*(state), griddim_*(state)\n# Known in OpenCL as:\nget_group_id,      get_local_size,    get_local_id,       get_num_groups  #  GPUArrays.gpu_call     Function .  Calls function  f  on the GPU.  A  must be an GPUArray and will help to dispatch to the correct GPU backend and supplies queues and contexts. Calls kernel with  kernel(state, args...) , where state is dependant on the backend and can be used for e.g getting an index into A with  linear_index(state) . Optionally, launch configuration can be supplied in the following way:  1) A single integer, indicating how many work items (total number of threads) you want to launch.\n    in this case `linear_index(state)` will be a number in the range 1:configuration\n2) Pass a tuple of integer tuples to define blocks and threads per blocks!  source  #  GPUArrays.linear_index     Method .  linear index in a GPU kernel (equal to  OpenCL.get_global_id)  source  #  GPUArrays.global_size     Method .  Global size == blockdim * griddim == total number of kernel execution  source  #  GPUArrays.@linearidx     Macro .  Macro form of  linear_index , which returns when out of bounds  source  #  GPUArrays.@cartesianidx     Macro .  Like  @linearidx , but returns an N-dimensional  NTuple{ndim(A), Cuint}  as index  source  #  GPUArrays.synchronize_threads     Method .  in CUDA terms  __synchronize  source  #  GPUArrays.device     Method .  Gets the device associated to the Array  A  source  #  GPUArrays.synchronize     Method .  Blocks until all operations are finished on  A  source", 
            "title": "Abstract GPU interface"
        }
    ]
}